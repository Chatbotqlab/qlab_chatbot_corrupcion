{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a90d0927",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "from datetime import datetime\n",
    "import ast # Para ast.literal_eval, más seguro que eval()\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1d7bdce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ruta del archivo CSV de entrada: c:\\Users\\LENOVO\\Documents\\GitHub\\qlab_chatbot_corrupcion\\data\\AC_total.xlsx - Sheet1.csv\n",
      "Ruta del archivo JSONL de salida: c:\\Users\\LENOVO\\Documents\\GitHub\\qlab_chatbot_corrupcion\\output\\salida_informes_consolidados_desde_csv.jsonl\n",
      "Archivo JSONL de informes consolidados 'c:\\Users\\LENOVO\\Documents\\GitHub\\qlab_chatbot_corrupcion\\output\\salida_informes_consolidados_desde_csv.jsonl' generado exitosamente.\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# --- Bloque para definir rutas dinámicamente y ejecutar la conversión ---\n",
    "\n",
    "# El notebook está en: .../QLAB_CHATBOT_CORRUPCION/procesamiento/src_json_optimizado/\n",
    "notebook_dir = os.getcwd()\n",
    "\n",
    "# Subimos dos niveles para llegar a la raíz del proyecto: QLAB_CHATBOT_CORRUPCION/\n",
    "project_root = os.path.abspath(os.path.join(notebook_dir, '..', '..'))\n",
    "\n",
    "# Nombres de los archivos\n",
    "# ¡ASEGÚRATE QUE ESTE ES EL NOMBRE CORRECTO DE TU ARCHIVO CSV DE ENTRADA!\n",
    "csv_input_filename = \"AC_total.xlsx - Sheet1.csv\" \n",
    "jsonl_output_filename = \"salida_informes_consolidados_desde_csv.jsonl\"\n",
    "\n",
    "# Construir rutas completas\n",
    "# Archivo CSV de entrada desde la carpeta 'data' del proyecto\n",
    "csv_input_path = os.path.join(project_root, 'data', csv_input_filename)\n",
    "\n",
    "# Archivo JSONL de salida a la carpeta 'output' del proyecto\n",
    "jsonl_output_path = os.path.join(project_root, 'output', jsonl_output_filename)\n",
    "\n",
    "# (Opcional) Imprime las rutas para verificar:\n",
    "print(f\"Ruta del archivo CSV de entrada: {csv_input_path}\")\n",
    "print(f\"Ruta del archivo JSONL de salida: {jsonl_output_path}\")\n",
    "\n",
    "# Llamada a la función principal\n",
    "convert_csv_reports_to_jsonl(csv_input_path, jsonl_output_path)\n",
    "# --- Fin del bloque de ejecución ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32590831",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def format_date_from_csv(date_val_str):\n",
    "    \"\"\"\n",
    "    Formatea fechas desde strings de CSV a YYYY-MM-DD.\n",
    "    \"\"\"\n",
    "    if pd.isna(date_val_str) or date_val_str == '':\n",
    "        return None\n",
    "    \n",
    "    # Intentar varios formatos comunes\n",
    "    formats_to_try = [\n",
    "        '%Y-%m-%d', '%d/%m/%Y', '%m/%d/%Y',\n",
    "        '%Y/%m/%d', '%d-%m-%Y', '%m-%d-%Y',\n",
    "        '%Y%m%d' # AAAA MM DD\n",
    "    ]\n",
    "    \n",
    "    for fmt in formats_to_try:\n",
    "        try:\n",
    "            return datetime.strptime(str(date_val_str).strip(), fmt).strftime('%Y-%m-%d')\n",
    "        except ValueError:\n",
    "            continue\n",
    "    \n",
    "    # Si ninguno de los formatos funciona, intentar con pd.to_datetime como último recurso\n",
    "    try:\n",
    "        dt_obj = pd.to_datetime(str(date_val_str).strip(), errors='coerce')\n",
    "        if pd.notna(dt_obj):\n",
    "            return dt_obj.strftime('%Y-%m-%d')\n",
    "    except Exception:\n",
    "        pass\n",
    "        \n",
    "    # print(f\"Advertencia: No se pudo parsear la fecha '{date_val_str}'. Se devuelve como string.\")\n",
    "    return str(date_val_str).strip() # Devuelve el string original si todo falla\n",
    "\n",
    "def clean_numero_informe(num_informe_str):\n",
    "    if pd.isna(num_informe_str) or num_informe_str == '':\n",
    "        return None\n",
    "    num_informe_str = str(num_informe_str).strip()\n",
    "    num_informe_str = re.sub(r\"^(N\\*|N'|N°|INFORME DE AUDITORÍA N\\*\\s*)\", \"\", num_informe_str, flags=re.IGNORECASE).strip()\n",
    "    num_informe_str = re.sub(r'\\s*-\\s*', '-', num_informe_str)\n",
    "    num_informe_str = num_informe_str.replace(\"%20\", \" \")\n",
    "    num_informe_str = re.sub(r'\\s+', ' ', num_informe_str)\n",
    "    num_informe_str = re.sub(r'\\s*-\\s*', '-', num_informe_str)\n",
    "    \n",
    "    match = re.search(r'(\\d+-\\d{4}(?:-\\d+-\\d+)?(?:-CG)?\\/[A-Z\\s]+-AC|\\d+-\\d{4}-\\d-\\d+)', num_informe_str, flags=re.IGNORECASE)\n",
    "    if match:\n",
    "        return match.group(1).strip().upper()\n",
    "    \n",
    "    match_simple = re.search(r'(\\d+-\\d{4})', num_informe_str)\n",
    "    if match_simple:\n",
    "        cleaned_simple_fallback = re.sub(r'[^\\w\\d\\s\\/-]', '', num_informe_str).strip()\n",
    "        if re.match(r'\\d+-\\d{4}.*', cleaned_simple_fallback):\n",
    "            return cleaned_simple_fallback.upper()\n",
    "        return match_simple.group(1).strip().upper()\n",
    "        \n",
    "    return re.sub(r'[^\\w\\d\\s\\/-]', '', num_informe_str).strip().upper()\n",
    "\n",
    "def create_report_id(numero_informe_limpio):\n",
    "    if not numero_informe_limpio:\n",
    "        return \"ID_REPORTE_DESCONOCIDO\"\n",
    "    report_id = numero_informe_limpio.replace(\"/\", \"_\")\n",
    "    report_id = report_id.replace(\"-CG_\", \"_\") \n",
    "    report_id = re.sub(r'_CG(?=_|$)', '', report_id)\n",
    "    report_id = report_id.replace(\"-\", \"_\")\n",
    "    return report_id.upper()\n",
    "\n",
    "def parse_responsabilidades_dict(resp_str):\n",
    "    parsed_resp = {'civil': False, 'penal': False, 'admin_ent': False, 'admin_pas': False}\n",
    "    if pd.isna(resp_str) or not isinstance(resp_str, str) or resp_str == '':\n",
    "        return parsed_resp\n",
    "    try:\n",
    "        resp_dict_raw = ast.literal_eval(resp_str)\n",
    "        if not isinstance(resp_dict_raw, dict): # Asegurarse que sea un diccionario\n",
    "            return parsed_resp\n",
    "            \n",
    "        parsed_resp['civil'] = bool(resp_dict_raw.get('Civil') and 'X' in resp_dict_raw.get('Civil',[]))\n",
    "        parsed_resp['penal'] = bool(resp_dict_raw.get('Penal') and 'X' in resp_dict_raw.get('Penal',[]))\n",
    "        parsed_resp['admin_ent'] = bool(resp_dict_raw.get('Adm. ENT') and 'X' in resp_dict_raw.get('Adm. ENT',[]))\n",
    "        \n",
    "        pas_marked = bool(resp_dict_raw.get('Adm. PAS') and 'X' in resp_dict_raw.get('Adm. PAS',[]))\n",
    "        admin_general_marked = bool(resp_dict_raw.get('Admin.') and 'X' in resp_dict_raw.get('Admin.',[])) # Para la columna 'Admin.'\n",
    "        parsed_resp['admin_pas'] = pas_marked or admin_general_marked\n",
    "        return parsed_resp\n",
    "    except (ValueError, SyntaxError) as e:\n",
    "        # print(f\"Error parseando responsabilidades con ast.literal_eval '{resp_str}': {e}\")\n",
    "        return parsed_resp\n",
    "    \n",
    "def clean_and_convert_monto(monto_str, default_if_empty='0'):\n",
    "    \"\"\"Limpia un string de monto y lo convierte a float.\"\"\"\n",
    "    if pd.isna(monto_str) or monto_str == '':\n",
    "        monto_str = default_if_empty\n",
    "    \n",
    "    cleaned_str = str(monto_str)\n",
    "    # Eliminar \"S/\", \"S.\", \"$\", etc. y espacios al principio/final\n",
    "    cleaned_str = re.sub(r'^(S\\/|S\\.|\\$)\\s*', '', cleaned_str).strip()\n",
    "    # Eliminar comas usadas como separadores de miles\n",
    "    cleaned_str = cleaned_str.replace(',', '')\n",
    "    # Eliminar espacios internos (ej. \"1 234.56\")\n",
    "    cleaned_str = cleaned_str.replace(' ', '')\n",
    "    \n",
    "    try:\n",
    "        return float(cleaned_str)\n",
    "    except ValueError:\n",
    "        # print(f\"Advertencia: No se pudo convertir el monto '{monto_str}' a float. Se devuelve None.\")\n",
    "        return None # O podrías devolver 0.0 si prefieres\n",
    "\n",
    "\n",
    "def convert_csv_reports_to_jsonl(csv_path, jsonl_path):\n",
    "    try:\n",
    "        # Leer el CSV, tratando todas las columnas como string para manejo inicial\n",
    "        # y usando na_filter=False para que las celdas vacías sean '' en lugar de NaN\n",
    "        df = pd.read_csv(csv_path, dtype=str, keep_default_na=False, na_filter=False)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: El archivo CSV '{csv_path}' no fue encontrado.\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(f\"Error al leer el archivo CSV: {e}\")\n",
    "        return\n",
    "\n",
    "    # --- Mapeo de Nombres de Columnas (AJUSTAR SEGÚN TU CSV) ---\n",
    "    col_map = {\n",
    "        'numero_informe_col': 'numero_informe',\n",
    "        'titulo_asunto_col': 'titulo_informe/asunto',\n",
    "        'objetivo_col': 'objetivo',\n",
    "        'observaciones_col': 'observaciones',\n",
    "        'recomendaciones_col': 'recomendaciones',\n",
    "        'entidad_auditada_col': 'entidad_auditada',\n",
    "        'fecha_emision_col': 'fecha_emision_informe',\n",
    "        'unidad_emite_col': 'unidad_emite_informe',\n",
    "        'distrito_col': 'distrito',\n",
    "        'provincia_col': 'provincia',\n",
    "        'region_col': 'region',\n",
    "        'modalidad_col': 'modalidad',\n",
    "        'periodo_inicio_col': 'inicio',\n",
    "        'periodo_fin_col': 'final',\n",
    "        'monto_auditado_col': 'monto_auditado', \n",
    "        'monto_examinado_col': 'monto_examinado',\n",
    "        'responsabilidades_dict_str_col': 'columnas', # String del dict de resp.\n",
    "        'dni_col': 'dni',\n",
    "        'nombres_persona_col': 'personas',\n",
    "        'resp_civil_col_individual': 'civil',\n",
    "        'resp_penal_col_individual': 'penal',\n",
    "        'resp_admin_col_individual': 'admin',\n",
    "        'resp_admin_ent_col_individual': 'adm_ent',\n",
    "        'resp_admin_pas_col_individual': 'adm_pas'\n",
    "    }\n",
    "\n",
    "    # Asegurarse de que las columnas existan, si no, no se podrá agrupar\n",
    "    if col_map['numero_informe_col'] not in df.columns:\n",
    "        print(f\"Error: La columna '{col_map['numero_informe_col']}' (para numero_informe) no se encuentra en el CSV.\")\n",
    "        return\n",
    "\n",
    "    df['numero_informe_limpio'] = df[col_map['numero_informe_col']].apply(clean_numero_informe)\n",
    "    df['report_id_temp'] = df['numero_informe_limpio'].apply(create_report_id)\n",
    "\n",
    "    df_valid_reports = df[df['numero_informe_limpio'].notna() & (df['numero_informe_limpio'] != '')].copy()\n",
    "    \n",
    "    if df_valid_reports.empty:\n",
    "        print(\"No se encontraron informes válidos para procesar.\")\n",
    "        return\n",
    "\n",
    "    # Definir get_col_val aquí una vez, antes del bucle de agrupación\n",
    "    def get_col_val(row, abstract_col_key, default=''):\n",
    "        actual_col_name = col_map.get(abstract_col_key)\n",
    "        if actual_col_name:\n",
    "            return str(row.get(actual_col_name, default)).strip()\n",
    "        # Fallback si abstract_col_key no está en col_map (podría ser un nombre de columna directo)\n",
    "        return str(row.get(abstract_col_key, default)).strip()\n",
    "\n",
    "    grouped = df_valid_reports.groupby('report_id_temp')\n",
    "\n",
    "    with open(jsonl_path, 'w', encoding='utf-8') as outfile:\n",
    "        for report_id, group_df in grouped:\n",
    "            if not report_id or report_id == \"ID_REPORTE_DESCONOCIDO\":\n",
    "                continue\n",
    "            \n",
    "            first_row = group_df.iloc[0]\n",
    "\n",
    "            # --- INICIO DE LÓGICA MODIFICADA PARA EXTRACCIÓN DE 'year' ---\n",
    "            year = None\n",
    "            # Usar el valor de 'numero_informe_limpio' de la primera fila del grupo.\n",
    "            # Si 'numero_informe_limpio' es None o no es string, get tratará '' como no-string y el if no entrará.\n",
    "            numero_informe_para_year = first_row.get('numero_informe_limpio', '')\n",
    "\n",
    "            if numero_informe_para_year and isinstance(numero_informe_para_year, str):\n",
    "                # Encontrar todas las secuencias de 4 dígitos delimitadas por no-dígitos o inicio/fin de cadena.\n",
    "                potential_year_strings = re.findall(r'\\b(\\d{4})\\b', numero_informe_para_year)\n",
    "                \n",
    "                valid_years_in_range = []\n",
    "                for y_str in potential_year_strings:\n",
    "                    try:\n",
    "                        candidate_y = int(y_str)\n",
    "                        if 2016 <= candidate_y <= 2022:\n",
    "                            valid_years_in_range.append(candidate_y)\n",
    "                    except ValueError:\n",
    "                        continue # Ignorar si no es un número\n",
    "                \n",
    "                if len(valid_years_in_range) == 1:\n",
    "                    # Exactamente un año válido encontrado en el rango\n",
    "                    year = valid_years_in_range[0]\n",
    "                elif len(valid_years_in_range) > 1:\n",
    "                    # Múltiples años válidos encontrados. Esto es ambiguo según tu requisito.\n",
    "                    print(f\"Advertencia [ID: {report_id}]: Múltiples años válidos (2016-2022) encontrados en \"\n",
    "                          f\"numero_informe_limpio '{numero_informe_para_year}': {valid_years_in_range}. \"\n",
    "                          f\"No se ha asignado un año debido a la ambigüedad.\")\n",
    "                    # 'year' permanece None\n",
    "                # else: len(valid_years_in_range) == 0\n",
    "                    # No se encontraron años en el rango válido. 'year' permanece None.\n",
    "            \n",
    "            # Solo imprimir advertencia si no se pudo asignar un año Y hubo un intento (numero_informe no vacío)\n",
    "            if year is None and numero_informe_para_year:\n",
    "                # La advertencia de múltiples años ya se imprimió arriba, así que nos enfocamos en 0 años válidos.\n",
    "                # (Se asume 'potential_year_strings' está definida si entramos al bloque if anterior)\n",
    "                num_valid_years = len(valid_years_in_range) if 'valid_years_in_range' in locals() else 0\n",
    "                if num_valid_years == 0:\n",
    "                    all_candidates = potential_year_strings if 'potential_year_strings' in locals() else \"ninguno (o no se procesó)\"\n",
    "                    print(f\"Advertencia [ID: {report_id}]: No se pudo determinar un año único y válido (2016-2022) \"\n",
    "                          f\"desde numero_informe_limpio: '{numero_informe_para_year}'. \"\n",
    "                          f\"Candidatos de 4 dígitos encontrados: {all_candidates}.\")\n",
    "            # --- FIN DE LÓGICA MODIFICADA PARA EXTRACCIÓN DE 'year' ---\n",
    "            \n",
    "            personas_implicadas_list = []\n",
    "            seen_dnis = set()\n",
    "            for _, p_row in group_df.iterrows():\n",
    "                dni = get_col_val(p_row, 'dni_col', '') \n",
    "                nombre = get_col_val(p_row, 'nombres_persona_col', '')\n",
    "                if dni and dni not in seen_dnis: \n",
    "                    personas_implicadas_list.append({\"dni\": dni, \"nombre\": nombre})\n",
    "                    seen_dnis.add(dni)\n",
    "\n",
    "            informe_resp = {'civil': False, 'penal': False, 'admin_ent': False, 'admin_pas': False}\n",
    "            consolidated_from_dict = False\n",
    "            for _, r_row in group_df.iterrows():\n",
    "                resp_dict_str = get_col_val(r_row, 'responsabilidades_dict_str_col', '')\n",
    "                if resp_dict_str:\n",
    "                    resp_fila_dict = parse_responsabilidades_dict(resp_dict_str)\n",
    "                    for resp_type_key in informe_resp.keys(): \n",
    "                        informe_resp[resp_type_key] = informe_resp[resp_type_key] or resp_fila_dict.get(resp_type_key, False)\n",
    "                    if any(resp_fila_dict.values()): \n",
    "                        consolidated_from_dict = True\n",
    "            \n",
    "            if not consolidated_from_dict: \n",
    "                for _, r_row in group_df.iterrows():\n",
    "                    informe_resp['civil'] = informe_resp['civil'] or (get_col_val(r_row,'resp_civil_col_individual','0') == '1')\n",
    "                    informe_resp['penal'] = informe_resp['penal'] or (get_col_val(r_row,'resp_penal_col_individual','0') == '1')\n",
    "                    informe_resp['admin_ent'] = informe_resp['admin_ent'] or (get_col_val(r_row, 'resp_admin_ent_col_individual','0') == '1')\n",
    "                    admin_general = (get_col_val(r_row,'resp_admin_col_individual','0') == '1')\n",
    "                    admin_pas_individual = (get_col_val(r_row, 'resp_admin_pas_col_individual','0') == '1')\n",
    "                    informe_resp['admin_pas'] = informe_resp['admin_pas'] or admin_pas_individual or admin_general\n",
    "\n",
    "            monto_auditado_str = get_col_val(first_row, 'monto_auditado_col')\n",
    "            monto_examinado_str = get_col_val(first_row, 'monto_examinado_col')\n",
    "\n",
    "            monto_auditado_float = clean_and_convert_monto(monto_auditado_str)\n",
    "            monto_examinado_float = clean_and_convert_monto(monto_examinado_str)\n",
    "\n",
    "           \n",
    "                       # --- PROCESAMIENTO ESPECÍFICO PARA REGIÓN Y PROVINCIA ---\n",
    "            \n",
    "            # REGIÓN\n",
    "            region_val_raw = get_col_val(first_row, 'region_col')\n",
    "            region_final = None # Valor por defecto\n",
    "\n",
    "            if region_val_raw and isinstance(region_val_raw, str):\n",
    "                # Primero, limpieza general: reemplazar \\n y normalizar espacios\n",
    "                cleaned_region = region_val_raw.replace(\"\\n\", \" \").strip()\n",
    "                cleaned_region = ' '.join(cleaned_region.split()) # Normaliza múltiples espacios a uno\n",
    "\n",
    "                # Ahora, la lógica específica\n",
    "                # Usamos re.IGNORECASE por si hay variaciones de mayúsculas/minúsculas\n",
    "                if re.search(r\"P\\s*\\.\\s*C\\s*\\.\\s*DEL\\s+CALLAO\", cleaned_region, re.IGNORECASE) or \\\n",
    "                   re.search(r\"Prov(incia)?\\s*(Constitucional)?\\s*del\\s+Callao\", cleaned_region, re.IGNORECASE): # Añadir más patrones si es necesario\n",
    "                    region_final = \"CALLAO\"\n",
    "                else:\n",
    "                    region_final = cleaned_region # Si no coincide con el patrón especial, usar el valor limpiado\n",
    "            elif region_val_raw: # Si no es string pero tiene valor (ej. numérico), convertir a string\n",
    "                region_final = str(region_val_raw)\n",
    "\n",
    "\n",
    "            # PROVINCIA\n",
    "            provincia_val_raw = get_col_val(first_row, 'provincia_col')\n",
    "            provincia_final = None # Valor por defecto\n",
    "\n",
    "            if provincia_val_raw and isinstance(provincia_val_raw, str):\n",
    "                cleaned_provincia = provincia_val_raw.replace(\"\\n\", \" \").strip()\n",
    "                cleaned_provincia = ' '.join(cleaned_provincia.split())\n",
    "\n",
    "                # Lógica similar para provincia si es necesario, o simplemente limpieza general\n",
    "                # Ejemplo de regla específica para provincia también:\n",
    "                if re.search(r\"PROV\\s*\\.\\s*CONST\\s*\\.\\s*DEL\\s+CALLAO\", cleaned_provincia, re.IGNORECASE) or \\\n",
    "                   re.search(r\"CALLAO\", cleaned_provincia, re.IGNORECASE): # Si ya dice \"CALLAO\" o similar\n",
    "                    provincia_final = \"CALLAO\"\n",
    "                # Podrías tener otras transformaciones específicas para provincia aquí\n",
    "                # Por ejemplo, si ves \"LIMA METROPOLITANA\" y quieres solo \"LIMA\"\n",
    "                # elif \"LIMA METROPOLITANA\" in cleaned_provincia.upper():\n",
    "                #     provincia_final = \"LIMA\"\n",
    "                else:\n",
    "                    provincia_final = cleaned_provincia\n",
    "            elif provincia_val_raw:\n",
    "                provincia_final = str(provincia_val_raw)\n",
    "                \n",
    "            # --- FIN DE PROCESAMIENTO ESPECÍFICO ---\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "            json_report_object = {\n",
    "                \"report_id\": report_id,\n",
    "                \"numero_informe\": first_row.get('numero_informe_limpio', None),\n",
    "                \"titulo_informe\": get_col_val(first_row, 'titulo_asunto_col').replace(\"\\n\", \" \"),\n",
    "                \"entidad_auditada\": get_col_val(first_row, 'entidad_auditada_col'),\n",
    "                \"region\": region_final,\n",
    "                \"provincia\": provincia_final,\n",
    "                \"distrito\": get_col_val(first_row, 'distrito_col') or None,\n",
    "                \"year\": year, \n",
    "                \"periodo_inicio\": format_date_from_csv(get_col_val(first_row, 'periodo_inicio_col')),\n",
    "                \"periodo_fin\": format_date_from_csv(get_col_val(first_row, 'periodo_fin_col')),\n",
    "                \"monto_auditado\": monto_auditado_float,\n",
    "                \"monto_examinado\": monto_examinado_float,\n",
    "                \"modalidad\": get_col_val(first_row, 'modalidad_col') or None,\n",
    "                \"fecha_emision\": format_date_from_csv(get_col_val(first_row, 'fecha_emision_col')),\n",
    "                \"unidad_emite\": get_col_val(first_row, 'unidad_emite_col') or None,\n",
    "                \"personas_implicadas_consolidado\": personas_implicadas_list,\n",
    "                \"responsabilidades_consolidadas\": informe_resp,\n",
    "                \"texto_objetivos_completo\": get_col_val(first_row, 'objetivo_col'),\n",
    "                \"texto_observaciones_completo\": get_col_val(first_row, 'observaciones_col'),\n",
    "                \"texto_recomendaciones_completo\": get_col_val(first_row, 'recomendaciones_col')\n",
    "            }\n",
    "    \n",
    "            outfile.write(json.dumps(json_report_object, ensure_ascii=False) + '\\n')\n",
    "\n",
    "    print(f\"Archivo JSONL de informes consolidados '{jsonl_path}' generado exitosamente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7122866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo JSONL de informes consolidados 'c:\\Users\\LENOVO\\Documents\\GitHub\\qlab_chatbot_corrupcion\\output\\salida_informes_consolidados_desde_csv.jsonl' generado exitosamente.\n"
     ]
    }
   ],
   "source": [
    "convert_csv_reports_to_jsonl(csv_input_path, jsonl_output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zoom",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
