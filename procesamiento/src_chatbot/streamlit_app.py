# procesamiento/src_chatbot/streamlit_app.py

# --- 1. IMPORTACIONES LIMPIAS (Corregido) ---
import os
import streamlit as st
from dotenv import load_dotenv
from openai import OpenAI


st.set_page_config(page_title="Chatbot Corrupci√≥n üí¨", layout="centered")

# Importar las funciones y variables de nuestra l√≥gica de chatbot
from chatbot_logic import (
    load_chunks_with_embeddings, 
    send_question_to_openai,
    system_prompt_v2
)

# --- 2. CARGA DE VARIABLES DE ENTORNO ---
load_dotenv()

# --- 3. CONFIGURACI√ìN DEL CLIENTE OPENAI (Corregido para local y deploy) ---
# Intenta obtener la clave de los secretos de Streamlit (para cuando est√© desplegada)
# Si no la encuentra, intenta obtenerla de las variables de entorno (para tu computadora local)
try:
    # Para despliegue en Streamlit Cloud
    api_key = st.secrets['OPENAI_API_KEY']
except (KeyError, FileNotFoundError):
    # Para desarrollo local (lee el archivo .env)
    api_key = os.getenv("OPENAI_API_KEY")

if not api_key:
    st.error("La API key de OpenAI no est√° configurada. Por favor, a√±√°dela a los secretos de Streamlit o a tu archivo .env.")
    st.stop()
else:
    client = OpenAI(api_key=api_key)


# --- 4. CARGA DE DATOS (Corregido) ---
@st.cache_data # Usa el cache para no recargar los datos en cada interacci√≥n
def load_data():
    """Funci√≥n para cargar los chunks CON EMBEDDINGS."""
    # Llama a la nueva funci√≥n de carga que viene de chatbot_logic.py
    chunks = load_chunks_with_embeddings()
    return chunks

# Carga los datos al iniciar la app
docs_chunks = load_data()

# Si no se cargan los datos, detiene la app con un error claro
if not docs_chunks:
    st.error("No se pudieron cargar los datos de los informes (chunks_with_embeddings.jsonl). La aplicaci√≥n no puede continuar. Aseg√∫rate de haber ejecutado primero el script de generaci√≥n de embeddings.")
    st.stop()


# --- 5. INTERFAZ DE USUARIO (UI) ---



with st.sidebar:
    # Ruta de imagen corregida para ser m√°s robusta
    st.image(".streamlit/logo.png", use_container_width=True)
    st.title('Chatbot Corrupci√≥n')
    st.markdown('''
    ## Sobre este Chatbot
    Bienvenido al **Chatbot Corrupci√≥n**. Esta herramienta te permite conversar con una base de datos de informes de auditor√≠a de la Contralor√≠a General de la Rep√∫blica del Per√∫, enfocados en gobiernos subnacionales durante el per√≠odo 2016-2022.
    
    **¬øC√≥mo usarlo?**
    - Haz preguntas espec√≠ficas sobre una regi√≥n, a√±o o tema.
    - Ejemplo: "¬øQu√© hallazgos hubo en Cusco durante el 2021?"
    - El chatbot buscar√° la informaci√≥n relevante en los informes y te dar√° un resumen.
    ''')
    st.markdown('Desarrollado por **Q-Lab**')

    if st.button("üóëÔ∏è Limpiar conversaci√≥n"):
        st.session_state.messages = [{"role": "assistant", "content": "Conversaci√≥n reiniciada. ¬øEn qu√© m√°s puedo ayudarte?"}]
        st.rerun()

def main():
    st.title("Chatbot Corrupci√≥n üí¨")
    st.markdown("Conversa con los informes de la contralor√≠a sobre corrupci√≥n en gobiernos subnacionales en Per√∫ (2016-2022).")
    st.write("---")

    # Inicializa el historial de chat si no existe
    if "messages" not in st.session_state:
        st.session_state.messages = [{"role": "assistant", "content": "Hola, soy el Chatbot Corrupci√≥n. ¬øEn qu√© puedo ayudarte?"}]

    # Muestra mensajes previos
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # Captura la entrada del usuario
    if user_input := st.chat_input("Escribe tu pregunta aqu√≠..."):
        st.session_state.messages.append({"role": "user", "content": user_input})
        with st.chat_message("user"):
            st.markdown(user_input)

        with st.spinner("Analizando informes y generando respuesta..."):
            # Prepara el historial para enviarlo a la funci√≥n de l√≥gica
            conversation_history = [
                msg for msg in st.session_state.messages[:-1] if msg["role"] != "system"
            ]

            # Llama a la funci√≥n de l√≥gica para obtener la respuesta
            response_text = send_question_to_openai(
                question=user_input,
                all_docs_chunks=docs_chunks,
                conversation_history=conversation_history,
                openai_client=client,
                system_prompt=system_prompt_v2
            )

            # A√±ade y muestra la respuesta del asistente
            assistant_message = {"role": "assistant", "content": response_text}
            st.session_state.messages.append(assistant_message)
            with st.chat_message("assistant"):
                 st.markdown(response_text)

# Punto de entrada para ejecutar la aplicaci√≥n
if __name__ == "__main__":
    main()